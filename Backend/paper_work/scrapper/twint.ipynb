{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import twint\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import os\n",
    "import datetime\n",
    "# import nest_asyncio\n",
    "# nest_asyncio.apply()\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('./twibot-22.csv')\n",
    "df['_id']=df['id'].map(lambda x: x[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id       860057\n",
       "label    860057\n",
       "_id      860057\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['label']=='human'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human\n",
      "1217628182611927040\n",
      "\u001b[H\u001b[2Jhuman\n",
      "2664730894\n",
      "\u001b[H\u001b[2Jhuman\n",
      "1266703520205549568\n",
      "\u001b[H\u001b[2Jhuman\n",
      "1089159225148882949\n",
      "\u001b[H\u001b[2Jbot\n",
      "36741729\n",
      "\u001b[H\u001b[2Jbot\n",
      "1365527332627247104\n",
      "fail\n",
      "bot\n",
      "1679822588\n",
      "\u001b[H\u001b[2Jhuman\n",
      "1519144464\n",
      "\u001b[H\u001b[2Jhuman\n",
      "15211869\n",
      "\u001b[H\u001b[2Jhuman\n",
      "1309034737756000256\n",
      "\u001b[H\u001b[2Jbot\n",
      "1341789703633178624\n",
      "fail\n",
      "human\n",
      "848975226\n",
      "\u001b[H\u001b[2Jhuman\n",
      "1109809482656149504\n",
      "\u001b[H\u001b[2Jhuman\n",
      "138814032\n",
      "\u001b[H\u001b[2Jhuman\n",
      "457554412\n",
      "\u001b[H\u001b[2Jhuman\n",
      "17899123\n",
      "\u001b[H\u001b[2Jbot\n",
      "2465283662\n",
      "\u001b[H\u001b[2Jhuman\n",
      "1467973039883182090\n",
      "\u001b[H\u001b[2Jhuman\n",
      "234059290\n",
      "\u001b[H\u001b[2Jhuman\n",
      "1142890104853106688\n",
      "\u001b[H\u001b[2Jhuman\n",
      "779266494270173187\n",
      "\u001b[H\u001b[2Jbot\n",
      "1275028426672549888\n",
      "fail\n",
      "human\n",
      "284870222\n",
      "\u001b[H\u001b[2Jhuman\n",
      "1280925874267787270\n",
      "\u001b[H\u001b[2Jhuman\n",
      "2599121383\n",
      "\u001b[H\u001b[2Jhuman\n",
      "912974971370115072\n",
      "\u001b[H\u001b[2Jhuman\n",
      "1322906536029626368\n",
      "\u001b[H\u001b[2Jhuman\n",
      "83389771\n",
      "\u001b[H\u001b[2Jhuman\n",
      "129211757\n",
      "\u001b[H\u001b[2Jhuman\n",
      "765845\n",
      "\u001b[H\u001b[2Jhuman\n",
      "804075344\n",
      "fail\n",
      "human\n",
      "935031277\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 32\u001b[0m\n\u001b[1;32m     26\u001b[0m user_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(list1, columns\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39musername\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mid\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdisplayname\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     27\u001b[0m                                        \u001b[39m'\u001b[39m\u001b[39mrenderedDescription\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mverified\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcreated\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     28\u001b[0m                                        \u001b[39m'\u001b[39m\u001b[39mfollowersCount\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfriendsCount\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mstatusesCount\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     29\u001b[0m                                        \u001b[39m'\u001b[39m\u001b[39mfavouritesCount\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlistedCount\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mmediaCount\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlocation\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     30\u001b[0m                                        \u001b[39m'\u001b[39m\u001b[39mprotected\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlink\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mprofileImageUrl\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     31\u001b[0m current_time \u001b[39m=\u001b[39m datetime\u001b[39m.\u001b[39mdatetime\u001b[39m.\u001b[39mnow()\n\u001b[0;32m---> 32\u001b[0m \u001b[39mfor\u001b[39;00m iteration, tweet \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(sntwitter\u001b[39m.\u001b[39mTwitterUserScraper(\u001b[39mid\u001b[39m)\u001b[39m.\u001b[39mget_items()):\n\u001b[1;32m     33\u001b[0m     \u001b[39mif\u001b[39;00m (justSome \u001b[39m==\u001b[39m \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m     34\u001b[0m             \u001b[39mif\u001b[39;00m (iteration\u001b[39m>\u001b[39m\u001b[39m100\u001b[39m):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/snscrape/modules/twitter.py:1538\u001b[0m, in \u001b[0;36mTwitterUserScraper.get_items\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \t\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_isUserId \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \t\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_query \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfrom:\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_user\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m-> 1538\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mget_items()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/snscrape/modules/twitter.py:1453\u001b[0m, in \u001b[0;36mTwitterSearchScraper.get_items\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1450\u001b[0m \t\u001b[39mdel\u001b[39;00m params[\u001b[39m'\u001b[39m\u001b[39mtweet_search_mode\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m   1451\u001b[0m \t\u001b[39mdel\u001b[39;00m paginationParams[\u001b[39m'\u001b[39m\u001b[39mtweet_search_mode\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m-> 1453\u001b[0m \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iter_api_data(\u001b[39m'\u001b[39m\u001b[39mhttps://api.twitter.com/2/search/adaptive.json\u001b[39m\u001b[39m'\u001b[39m, _TwitterAPIType\u001b[39m.\u001b[39mV2, params, paginationParams, cursor \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cursor):\n\u001b[1;32m   1454\u001b[0m \t\u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_v2_timeline_instructions_to_tweets(obj)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/snscrape/modules/twitter.py:720\u001b[0m, in \u001b[0;36m_TwitterAPIScraper._iter_api_data\u001b[0;34m(self, endpoint, apiType, params, paginationParams, cursor, direction)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m \t_logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mRetrieving scroll page \u001b[39m\u001b[39m{\u001b[39;00mcursor\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 720\u001b[0m \tobj \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_api_data(endpoint, apiType, reqParams)\n\u001b[1;32m    721\u001b[0m \t\u001b[39myield\u001b[39;00m obj\n\u001b[1;32m    723\u001b[0m \t\u001b[39m# No data format test, just a hard and loud crash if anything's wrong :-)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/snscrape/modules/twitter.py:690\u001b[0m, in \u001b[0;36m_TwitterAPIScraper._get_api_data\u001b[0;34m(self, endpoint, apiType, params)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[39mif\u001b[39;00m apiType \u001b[39mis\u001b[39;00m _TwitterAPIType\u001b[39m.\u001b[39mGRAPHQL:\n\u001b[1;32m    689\u001b[0m \tparams \u001b[39m=\u001b[39m urllib\u001b[39m.\u001b[39mparse\u001b[39m.\u001b[39murlencode({\u001b[39m'\u001b[39m\u001b[39mvariables\u001b[39m\u001b[39m'\u001b[39m: json\u001b[39m.\u001b[39mdumps(params, separators \u001b[39m=\u001b[39m (\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m'\u001b[39m))}, quote_via \u001b[39m=\u001b[39m urllib\u001b[39m.\u001b[39mparse\u001b[39m.\u001b[39mquote)\n\u001b[0;32m--> 690\u001b[0m r \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get(endpoint, params \u001b[39m=\u001b[39;49m params, headers \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apiHeaders, responseOkCallback \u001b[39m=\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_api_response)\n\u001b[1;32m    691\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    692\u001b[0m \tobj \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/snscrape/base.py:221\u001b[0m, in \u001b[0;36mScraper._get\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 221\u001b[0m \t\u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_request(\u001b[39m'\u001b[39;49m\u001b[39mGET\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/snscrape/base.py:178\u001b[0m, in \u001b[0;36mScraper._request\u001b[0;34m(self, method, url, params, data, headers, timeout, responseOkCallback, allowRedirects, proxies)\u001b[0m\n\u001b[1;32m    176\u001b[0m \tlogger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m... with environmentSettings: \u001b[39m\u001b[39m{\u001b[39;00menvironmentSettings\u001b[39m!r}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 178\u001b[0m \tr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_session\u001b[39m.\u001b[39;49msend(req, allow_redirects \u001b[39m=\u001b[39;49m allowRedirects, timeout \u001b[39m=\u001b[39;49m timeout, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49menvironmentSettings)\n\u001b[1;32m    179\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mRequestException \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    180\u001b[0m \t\u001b[39mif\u001b[39;00m attempt \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_retries:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    698\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[1;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    704\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/requests/adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    488\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[0;32m--> 489\u001b[0m         resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[1;32m    490\u001b[0m             method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[1;32m    491\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    492\u001b[0m             body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[1;32m    493\u001b[0m             headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[1;32m    494\u001b[0m             redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    495\u001b[0m             assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    496\u001b[0m             preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    497\u001b[0m             decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    498\u001b[0m             retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[1;32m    499\u001b[0m             timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m    500\u001b[0m         )\n\u001b[1;32m    502\u001b[0m     \u001b[39m# Send the request.\u001b[39;00m\n\u001b[1;32m    503\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(conn, \u001b[39m\"\u001b[39m\u001b[39mproxy_pool\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:699\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    698\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 699\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    700\u001b[0m     conn,\n\u001b[1;32m    701\u001b[0m     method,\n\u001b[1;32m    702\u001b[0m     url,\n\u001b[1;32m    703\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[1;32m    704\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[1;32m    705\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m    706\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[1;32m    707\u001b[0m )\n\u001b[1;32m    709\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    710\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    711\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    712\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[1;32m    713\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:445\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    440\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[1;32m    441\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    442\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    443\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    444\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m--> 445\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    446\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    447\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[0;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:440\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m    438\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[1;32m    439\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 440\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[1;32m    441\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    442\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[1;32m    443\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[1;32m    444\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m    445\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1372\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1373\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1374\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[1;32m   1375\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[1;32m   1376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[1;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[1;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/http/client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[1;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3.10/socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1274\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1271\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1272\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[1;32m   1273\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[0;32m-> 1274\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[1;32m   1275\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1276\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[0;32m/usr/lib/python3.10/ssl.py:1130\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1128\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1129\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1130\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[1;32m   1131\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1132\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "justSome=True\n",
    "j=0\n",
    "final_df=pd.DataFrame()\n",
    "for id,label in zip( df['_id'],df['label']):\n",
    "    user_tweets_list=[]\n",
    "    \n",
    "    list1 = []\n",
    "    id =int(id)\n",
    "    \n",
    "    scrapper = sntwitter.TwitterProfileScraper(id)\n",
    "    # print(scrapper.is_valid_username())\n",
    "    try:\n",
    "        user = scrapper.entity\n",
    "        list1.append([user.username, user.id, label, user.displayname,\n",
    "                      user.renderedDescription, user.verified, user.created,\n",
    "                      user.followersCount, user.friendsCount, user.statusesCount,\n",
    "                      user.favouritesCount, user.listedCount, user.mediaCount, user.location,\n",
    "                      user.protected, user.link, user.profileImageUrl])\n",
    "\n",
    "    except:\n",
    "        print('fail')\n",
    "        continue\n",
    "\n",
    "    user_df = pd.DataFrame(list1, columns=['username', 'id', 'label', 'displayname',\n",
    "                                           'renderedDescription', 'verified', 'created',\n",
    "                                           'followersCount', 'friendsCount', 'statusesCount',\n",
    "                                           'favouritesCount', 'listedCount', 'mediaCount', 'location',\n",
    "                                           'protected', 'link', 'profileImageUrl'])\n",
    "    current_time = datetime.datetime.now()\n",
    "    for iteration, tweet in enumerate(sntwitter.TwitterUserScraper(id).get_items()):\n",
    "        if (justSome == True):\n",
    "                if (iteration>100):\n",
    "                    break\n",
    "            # print(tweet.)\n",
    "        tweetItem = [tweet.date, tweet.id, tweet.rawContent, tweet.user.username, tweet.lang,\n",
    "                        tweet.hashtags, tweet.replyCount, tweet.retweetCount, tweet.likeCount,\n",
    "                        tweet.quoteCount , tweet.media, tweet.sourceLabel, tweet.quotedTweet, tweet.mentionedUsers]\n",
    "            \n",
    "        user_tweets_list.append(tweetItem)\n",
    "        \n",
    "    user_tweets_df = pd.DataFrame(user_tweets_list, columns=['DateTime', 'TweetId', 'Text', 'Username', 'Language',\n",
    "                        'Hashtags','ReplyCount','RetweetCount','LikeCount',\n",
    "                        'QuoteCount','Media','Source','quotedTweet','mentionedUsers'])\n",
    "    SourceList = user_tweets_df['Source'].unique().tolist()\n",
    "    userDict = user_df.to_dict('records')[0]\n",
    "    hashtagList=[]\n",
    "    mentionList=[]\n",
    "    for taglist in user_tweets_df['Hashtags']:\n",
    "        if (taglist):\n",
    "            for tag in taglist:\n",
    "                hashtagList.append(tag)\n",
    "\n",
    "    for mentions in user_tweets_df['mentionedUsers']:\n",
    "        if (mentions):\n",
    "            for mention in mentions:\n",
    "                mentionList.append(mention.username)\n",
    "\n",
    "    user_df['totalReplyCount'] = user_tweets_df['ReplyCount'].sum() or 0\n",
    "    user_df['totalRetweetCount'] = user_tweets_df['RetweetCount'].sum() or 0\n",
    "    user_df['totalLikeCount'] = user_tweets_df['LikeCount'].sum() or 0\n",
    "    user_df['totalQuoteCount'] = user_tweets_df['QuoteCount'].sum() or 0\n",
    "    user_df['totalSource'] = len(\n",
    "        user_tweets_df['Source'].unique().tolist()) or 0\n",
    "\n",
    "    user_df.to_csv('BotAccout.csv', mode='a', header=False,index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Twitter for iPhone', 'Instagram', 'Twitter Web App',\n",
       "       'Salsa Social Publishing', 'Twitter Web Client', 'Product Hunt'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df\n",
    "user_tweets_df['Source'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [32], line 10\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[39mreturn\u001b[39;00m i \u001b[39m*\u001b[39m i\n\u001b[1;32m      8\u001b[0m \u001b[39m# for i in range(10000000):\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[39m# process(i)\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m results \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)(delayed(process)(i) \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(\u001b[39m10000000\u001b[39;49m))\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(results)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/joblib/parallel.py:1061\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1061\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mretrieve()\n\u001b[1;32m   1062\u001b[0m \u001b[39m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m elapsed_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_start_time\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/joblib/parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    932\u001b[0m \u001b[39m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m    933\u001b[0m \u001b[39m# we empty it and Python list are not thread-safe by default hence\u001b[39;00m\n\u001b[1;32m    934\u001b[0m \u001b[39m# the use of the lock\u001b[39;00m\n\u001b[0;32m--> 935\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    936\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39mpop(\u001b[39m0\u001b[39m)\n\u001b[1;32m    938\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "exception calling callback for <Future at 0x7f580d2d0460 state=finished returned list>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/externals/loky/_base.py\", line 625, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/parallel.py\", line 366, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/parallel.py\", line 799, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/_parallel_backends.py\", line 531, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "AttributeError: 'NoneType' object has no attribute 'submit'\n",
      "exception calling callback for <Future at 0x7f580d010910 state=finished raised PicklingError>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/externals/loky/backend/queues.py\", line 153, in _feed\n",
      "    obj_ = dumps(obj, reducers=reducers)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/externals/loky/backend/reduction.py\", line 271, in dumps\n",
      "    dump(obj, buf, reducers=reducers, protocol=protocol)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/externals/loky/backend/reduction.py\", line 264, in dump\n",
      "    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/externals/cloudpickle/cloudpickle_fast.py\", line 563, in dump\n",
      "    return Pickler.dump(self, obj)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/parallel.py\", line 267, in __reduce__\n",
      "    self._reducer_callback()\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/parallel.py\", line 993, in _batched_calls_reducer_callback\n",
      "    self._backend._workers._temp_folder_manager.set_current_context(  # noqa\n",
      "AttributeError: 'NoneType' object has no attribute '_temp_folder_manager'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/externals/loky/_base.py\", line 625, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/parallel.py\", line 366, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/parallel.py\", line 799, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/_parallel_backends.py\", line 531, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "AttributeError: 'NoneType' object has no attribute 'submit'\n",
      "exception calling callback for <Future at 0x7f5822fbdc90 state=finished raised PicklingError>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/externals/loky/backend/queues.py\", line 153, in _feed\n",
      "    obj_ = dumps(obj, reducers=reducers)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/externals/loky/backend/reduction.py\", line 271, in dumps\n",
      "    dump(obj, buf, reducers=reducers, protocol=protocol)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/externals/loky/backend/reduction.py\", line 264, in dump\n",
      "    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/externals/cloudpickle/cloudpickle_fast.py\", line 563, in dump\n",
      "    return Pickler.dump(self, obj)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/parallel.py\", line 267, in __reduce__\n",
      "    self._reducer_callback()\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/parallel.py\", line 993, in _batched_calls_reducer_callback\n",
      "    self._backend._workers._temp_folder_manager.set_current_context(  # noqa\n",
      "AttributeError: 'NoneType' object has no attribute '_temp_folder_manager'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/externals/loky/_base.py\", line 625, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/parallel.py\", line 366, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/parallel.py\", line 799, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/_parallel_backends.py\", line 531, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "AttributeError: 'NoneType' object has no attribute 'submit'\n",
      "exception calling callback for <Future at 0x7f580e363160 state=finished raised PicklingError>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/externals/loky/backend/queues.py\", line 153, in _feed\n",
      "    obj_ = dumps(obj, reducers=reducers)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/externals/loky/backend/reduction.py\", line 271, in dumps\n",
      "    dump(obj, buf, reducers=reducers, protocol=protocol)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/externals/loky/backend/reduction.py\", line 264, in dump\n",
      "    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/externals/cloudpickle/cloudpickle_fast.py\", line 563, in dump\n",
      "    return Pickler.dump(self, obj)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/parallel.py\", line 267, in __reduce__\n",
      "    self._reducer_callback()\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/parallel.py\", line 993, in _batched_calls_reducer_callback\n",
      "    self._backend._workers._temp_folder_manager.set_current_context(  # noqa\n",
      "AttributeError: 'NoneType' object has no attribute '_temp_folder_manager'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/externals/loky/_base.py\", line 625, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/parallel.py\", line 366, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/parallel.py\", line 799, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/_parallel_backends.py\", line 531, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "AttributeError: 'NoneType' object has no attribute 'submit'\n",
      "exception calling callback for <Future at 0x7f580eb4be20 state=finished raised PicklingError>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/externals/loky/backend/queues.py\", line 153, in _feed\n",
      "    obj_ = dumps(obj, reducers=reducers)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/externals/loky/backend/reduction.py\", line 271, in dumps\n",
      "    dump(obj, buf, reducers=reducers, protocol=protocol)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/externals/loky/backend/reduction.py\", line 264, in dump\n",
      "    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/externals/cloudpickle/cloudpickle_fast.py\", line 563, in dump\n",
      "    return Pickler.dump(self, obj)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/parallel.py\", line 267, in __reduce__\n",
      "    self._reducer_callback()\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/parallel.py\", line 993, in _batched_calls_reducer_callback\n",
      "    self._backend._workers._temp_folder_manager.set_current_context(  # noqa\n",
      "AttributeError: 'NoneType' object has no attribute '_temp_folder_manager'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/externals/loky/_base.py\", line 625, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/parallel.py\", line 366, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/parallel.py\", line 799, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/_parallel_backends.py\", line 531, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "AttributeError: 'NoneType' object has no attribute 'submit'\n",
      "exception calling callback for <Future at 0x7f580eb4bf40 state=finished raised PicklingError>\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/externals/loky/backend/queues.py\", line 153, in _feed\n",
      "    obj_ = dumps(obj, reducers=reducers)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/externals/loky/backend/reduction.py\", line 271, in dumps\n",
      "    dump(obj, buf, reducers=reducers, protocol=protocol)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/externals/loky/backend/reduction.py\", line 264, in dump\n",
      "    _LokyPickler(file, reducers=reducers, protocol=protocol).dump(obj)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/externals/cloudpickle/cloudpickle_fast.py\", line 563, in dump\n",
      "    return Pickler.dump(self, obj)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/parallel.py\", line 267, in __reduce__\n",
      "    self._reducer_callback()\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/parallel.py\", line 993, in _batched_calls_reducer_callback\n",
      "    self._backend._workers._temp_folder_manager.set_current_context(  # noqa\n",
      "AttributeError: 'NoneType' object has no attribute '_temp_folder_manager'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/externals/loky/_base.py\", line 625, in _invoke_callbacks\n",
      "    callback(self)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/parallel.py\", line 366, in __call__\n",
      "    self.parallel.dispatch_next()\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/parallel.py\", line 799, in dispatch_next\n",
      "    if not self.dispatch_one_batch(self._original_iterator):\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/parallel.py\", line 866, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/parallel.py\", line 784, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/lib/python3/dist-packages/joblib/_parallel_backends.py\", line 531, in apply_async\n",
      "    future = self._workers.submit(SafeFunction(func))\n",
      "AttributeError: 'NoneType' object has no attribute 'submit'\n"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "def process(i):\n",
    "    return i * i\n",
    "\n",
    "\n",
    "# for i in range(10000000):\n",
    "    # process(i)\n",
    "results = Parallel(n_jobs=5)(delayed(process)(i) for i in range(10000000))\n",
    "print(results)  # prints [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1217628182611927040\n",
      "2664730894\n",
      "1266703520205549568\n",
      "1089159225148882949\n",
      "36741729\n",
      "1365527332627247104\n",
      "fail\n",
      "1679822588\n",
      "1519144464\n",
      "15211869\n",
      "1309034737756000256\n"
     ]
    }
   ],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "list1=[]\n",
    "# val = val = sntwitter.TwitterUserScraper(779266494270173187)\n",
    "# df['data']=df['_id'].map(lambda x: sntwitter.TwitterUserScraper(x))\n",
    "for id in df['id'][:10]:\n",
    "    id = id[1:]\n",
    "    # sntwitter.User\n",
    "    scrapper = sntwitter.TwitterProfileScraper(int(id))\n",
    "    print(id)\n",
    "    try:\n",
    "        user=scrapper.entity\n",
    "        # declare a username\n",
    "        # for i, tweet in enumerate(scrapper.get_items()):\n",
    "        list1.append([user.username, user.id, user.displayname,\n",
    "              user.renderedDescription, user.verified, user.created, \n",
    "              user.followersCount, user.friendsCount, user.statusesCount,\n",
    "               user.favouritesCount, user.listedCount, user.mediaCount,user.location,\n",
    "              user.protected, user.link, user.profileImageUrl])\n",
    "            # break\n",
    "    #tweets loop\n",
    "\n",
    "    # twwts df\n",
    "    # calc\n",
    "    #uuser_df\n",
    "       \n",
    "    except:\n",
    "        print('fail')\n",
    "\n",
    "    user_df = pd.DataFrame(list1, columns=['username', 'id', 'displayname',\n",
    "                                          'renderedDescription', 'verified', 'created',\n",
    "                                          'followersCount', 'friendsCount', 'statusesCount',\n",
    "                                          'favouritesCount', 'listedCount', 'mediaCount', 'location',\n",
    "                                          'protected', 'link', 'profileImageUrl'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "def profileAnalyis(username, justOneYear):\n",
    "    user_tweets_list=[]\n",
    "    list1 = []\n",
    "    scrapper = sntwitter.TwitterProfileScraper(username)\n",
    "    # print(scrapper.is_valid_username())\n",
    "    try:\n",
    "        user = scrapper.entity\n",
    "        list1.append([user.username, user.id, user.displayname,\n",
    "                      user.renderedDescription, user.verified, user.created,\n",
    "                      user.followersCount, user.friendsCount, user.statusesCount,\n",
    "                      user.favouritesCount, user.listedCount, user.mediaCount, user.location,\n",
    "                      user.protected, user.link, user.profileImageUrl])\n",
    "\n",
    "    except:\n",
    "        print('fail')\n",
    "        return None\n",
    "\n",
    "    user_df = pd.DataFrame(list1, columns=['username', 'id', 'displayname',\n",
    "                                           'renderedDescription', 'verified', 'created',\n",
    "                                           'followersCount', 'friendsCount', 'statusesCount',\n",
    "                                           'favouritesCount', 'listedCount', 'mediaCount', 'location',\n",
    "                                           'protected', 'link', 'profileImageUrl'])\n",
    "    current_time = datetime.datetime.now()\n",
    "    for i, tweet in enumerate(sntwitter.TwitterUserScraper(username).get_items()):\n",
    "            if (justOneYear==True):\n",
    "                if ((current_time.year-tweet.date.year)):\n",
    "                    # print('year end')\n",
    "                    break\n",
    "            # print(tweet.)\n",
    "            tweetItem = [tweet.date, tweet.id, tweet.rawContent, tweet.user.username, tweet.lang,\n",
    "                        tweet.hashtags, tweet.replyCount, tweet.retweetCount, tweet.likeCount,\n",
    "                        tweet.quoteCount , tweet.media, tweet.sourceLabel, tweet.quotedTweet, tweet.mentionedUsers]\n",
    "            # print(tweetItem)\n",
    "            \n",
    "            user_tweets_list.append(tweetItem)\n",
    "        \n",
    "    # print(user_tweets_list[0])\n",
    "    user_tweets_df = pd.DataFrame(user_tweets_list, columns=['DateTime', 'TweetId', 'Text', 'Username', 'Language',\n",
    "                        'Hashtags','ReplyCount','RetweetCount','LikeCount',\n",
    "                        'QuoteCount','Media','Source','quotedTweet','mentionedUsers'])\n",
    "\n",
    "\n",
    "    user_tweets_df['Hour'] = user_tweets_df['DateTime'].dt.hour\n",
    "\n",
    "    user_tweets_df['Year'] = user_tweets_df['DateTime'].dt.year\n",
    "\n",
    "    user_tweets_df['Month'] = user_tweets_df['DateTime'].dt.month\n",
    "\n",
    "    user_tweets_df['MonthName'] = user_tweets_df['DateTime'].dt.month_name()\n",
    "\n",
    "    user_tweets_df['MonthDay'] = user_tweets_df['DateTime'].dt.day\n",
    "\n",
    "    user_tweets_df['DayName'] = user_tweets_df['DateTime'].dt.day_name()\n",
    "    user_tweets_df['InteractionRating'] = (user_tweets_df['LikeCount'])+(\n",
    "        user_tweets_df['RetweetCount']*2)+(user_tweets_df['ReplyCount']*3)\n",
    "\n",
    "    user_tweets_df['Week'] = user_tweets_df['DateTime'].dt.day_of_year/7\n",
    "    user_tweets_df['Week'] = user_tweets_df['Week'].apply(np.ceil)\n",
    "    user_tweets_df['Week'] = user_tweets_df['Week'].astype(int)\n",
    "\n",
    "    user_tweets_df['Date'] = [d.date() for d in user_tweets_df['DateTime']]\n",
    "\n",
    "    user_tweets_df['Time'] = [d.time() for d in user_tweets_df['DateTime']]\n",
    "\n",
    "\n",
    "    lastYearTweets = user_tweets_df[user_tweets_df['Year']\n",
    "                                    == user_tweets_df['Year'].max()]\n",
    "\n",
    "    lastMonthTweets = lastYearTweets[lastYearTweets['Month']\n",
    "                                    == lastYearTweets['Month'].max()]\n",
    "\n",
    "    lastweekTweets = lastMonthTweets[lastMonthTweets['Week']\n",
    "                                    == lastMonthTweets['Week'].max()]\n",
    "    mostInteractedLastYear = lastYearTweets[lastYearTweets['InteractionRating']\n",
    "                                            == lastYearTweets['InteractionRating'].max()]\n",
    "\n",
    "\n",
    "    mostInteractedLastWeek = lastweekTweets[lastweekTweets['InteractionRating']\n",
    "                                            == lastweekTweets['InteractionRating'].max()]\n",
    "\n",
    "    mostInteractedLastMonth = lastMonthTweets[lastMonthTweets['InteractionRating']\n",
    "                                            == lastMonthTweets['InteractionRating'].max()]\n",
    "\n",
    "    scrapper = sntwitter.TwitterProfileScraper(username)\n",
    "\n",
    "\n",
    "    \n",
    "    SourceList = user_tweets_df['Source'].unique().tolist()\n",
    "\n",
    "\n",
    "    user_df['sources'] = [SourceList]\n",
    "    userDict = user_df.to_dict('records')[0]\n",
    "    LastYearDict = mostInteractedLastYear.to_dict('records')[0]\n",
    "    LastWeekDict = mostInteractedLastWeek.to_dict('records')[0]\n",
    "    LastMonthDict = mostInteractedLastMonth.to_dict('records')[0]\n",
    "    userDict['mostInteractedLastMonth'] = LastMonthDict\n",
    "    userDict['mostInteractedLastWeek'] = LastWeekDict\n",
    "    userDict['mostInteractedLastYear'] = LastYearDict\n",
    "    TweetTimeline = user_tweets_df['DateTime'].to_list()\n",
    "    TweetTimeline\n",
    "    userDict['TweetTimeline'] = TweetTimeline\n",
    "    return userDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fail\n"
     ]
    }
   ],
   "source": [
    "profileAnalyis('ctalhaahmad',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user_tweets_list=[]\n",
    "current_time = datetime.datetime.now()\n",
    "justOneYear = False\n",
    "username = 'ctalhaahmad'\n",
    "for i, tweet in enumerate(sntwitter.TwitterUserScraper(username).get_items()):\n",
    "        if (justOneYear==True):\n",
    "            if ((current_time.year-tweet.date.year)):\n",
    "                print('year end')\n",
    "                break\n",
    "        # print(tweet.)\n",
    "        tweetItem = [tweet.date, tweet.id, tweet.rawContent, tweet.user.username, tweet.lang,\n",
    "                     tweet.hashtags, tweet.replyCount, tweet.retweetCount, tweet.likeCount,\n",
    "                     tweet.quoteCount , tweet.media, tweet.sourceLabel, tweet.quotedTweet, tweet.mentionedUsers]\n",
    "        # print(tweetItem)\n",
    "        \n",
    "        user_tweets_list.append(tweetItem)\n",
    "    \n",
    "# print(user_tweets_list[0])\n",
    "user_tweets_df = pd.DataFrame(user_tweets_list, columns=['DateTime', 'TweetId', 'Text', 'Username', 'Language',\n",
    "                    'Hashtags','ReplyCount','RetweetCount','LikeCount',\n",
    "                    'QuoteCount','Media','Source','quotedTweet','mentionedUsers'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_tweets_df_copy=user_tweets_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>TweetId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>Language</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>ReplyCount</th>\n",
       "      <th>RetweetCount</th>\n",
       "      <th>LikeCount</th>\n",
       "      <th>QuoteCount</th>\n",
       "      <th>...</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>MonthName</th>\n",
       "      <th>MonthDay</th>\n",
       "      <th>DayName</th>\n",
       "      <th>InteractionRating</th>\n",
       "      <th>Week</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-02 23:13:02+00:00</td>\n",
       "      <td>1610051569399070721</td>\n",
       "      <td>I just played a stalemate draw with a +34 adva...</td>\n",
       "      <td>cTalhaAhmad</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>2</td>\n",
       "      <td>Monday</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>23:13:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   DateTime              TweetId  \\\n",
       "2 2023-01-02 23:13:02+00:00  1610051569399070721   \n",
       "\n",
       "                                                Text     Username Language  \\\n",
       "2  I just played a stalemate draw with a +34 adva...  cTalhaAhmad       en   \n",
       "\n",
       "  Hashtags  ReplyCount  RetweetCount  LikeCount  QuoteCount  ... Hour  Year  \\\n",
       "2     None           1             0          0           0  ...   23  2023   \n",
       "\n",
       "  Month MonthName  MonthDay  DayName  InteractionRating  Week        Date  \\\n",
       "2     1   January         2   Monday                  3     1  2023-01-02   \n",
       "\n",
       "       Time  \n",
       "2  23:13:02  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "lastYearTweets = user_tweets_df[user_tweets_df['Year']\n",
    "                                == user_tweets_df['Year'].max()]\n",
    "\n",
    "lastMonthTweets = lastYearTweets[lastYearTweets['Month']\n",
    "                                 == lastYearTweets['Month'].max()]\n",
    "\n",
    "lastweekTweets = lastMonthTweets[lastMonthTweets['Week']\n",
    "                                 == lastMonthTweets['Week'].max()]\n",
    "mostInteractedLastYear = lastYearTweets[lastYearTweets['InteractionRating']\n",
    "                                        == lastYearTweets['InteractionRating'].max()]\n",
    "\n",
    "\n",
    "mostInteractedLastWeek = lastweekTweets[lastweekTweets['InteractionRating']\n",
    "                                        == lastweekTweets['InteractionRating'].max()]\n",
    "\n",
    "mostInteractedLastMonth = lastMonthTweets[lastMonthTweets['InteractionRating']\n",
    "                                          == lastMonthTweets['InteractionRating'].max()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>TweetId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>Language</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>ReplyCount</th>\n",
       "      <th>RetweetCount</th>\n",
       "      <th>LikeCount</th>\n",
       "      <th>QuoteCount</th>\n",
       "      <th>...</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>MonthName</th>\n",
       "      <th>MonthDay</th>\n",
       "      <th>DayName</th>\n",
       "      <th>InteractionRating</th>\n",
       "      <th>Week</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-02 23:13:02+00:00</td>\n",
       "      <td>1610051569399070721</td>\n",
       "      <td>I just played a stalemate draw with a +34 adva...</td>\n",
       "      <td>cTalhaAhmad</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>2</td>\n",
       "      <td>Monday</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>23:13:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   DateTime              TweetId  \\\n",
       "2 2023-01-02 23:13:02+00:00  1610051569399070721   \n",
       "\n",
       "                                                Text     Username Language  \\\n",
       "2  I just played a stalemate draw with a +34 adva...  cTalhaAhmad       en   \n",
       "\n",
       "  Hashtags  ReplyCount  RetweetCount  LikeCount  QuoteCount  ... Hour  Year  \\\n",
       "2     None           1             0          0           0  ...   23  2023   \n",
       "\n",
       "  Month MonthName  MonthDay  DayName  InteractionRating  Week        Date  \\\n",
       "2     1   January         2   Monday                  3     1  2023-01-02   \n",
       "\n",
       "       Time  \n",
       "2  23:13:02  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mostInteractedLastWeek\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DateTime</th>\n",
       "      <th>TweetId</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>Language</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>ReplyCount</th>\n",
       "      <th>RetweetCount</th>\n",
       "      <th>LikeCount</th>\n",
       "      <th>QuoteCount</th>\n",
       "      <th>...</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>MonthName</th>\n",
       "      <th>MonthDay</th>\n",
       "      <th>DayName</th>\n",
       "      <th>InteractionRating</th>\n",
       "      <th>Week</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-01-02 23:13:02+00:00</td>\n",
       "      <td>1610051569399070721</td>\n",
       "      <td>I just played a stalemate draw with a +34 adva...</td>\n",
       "      <td>cTalhaAhmad</td>\n",
       "      <td>en</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>January</td>\n",
       "      <td>2</td>\n",
       "      <td>Monday</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-01-02</td>\n",
       "      <td>23:13:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   DateTime              TweetId  \\\n",
       "2 2023-01-02 23:13:02+00:00  1610051569399070721   \n",
       "\n",
       "                                                Text     Username Language  \\\n",
       "2  I just played a stalemate draw with a +34 adva...  cTalhaAhmad       en   \n",
       "\n",
       "  Hashtags  ReplyCount  RetweetCount  LikeCount  QuoteCount  ... Hour  Year  \\\n",
       "2     None           1             0          0           0  ...   23  2023   \n",
       "\n",
       "  Month MonthName  MonthDay  DayName  InteractionRating  Week        Date  \\\n",
       "2     1   January         2   Monday                  3     1  2023-01-02   \n",
       "\n",
       "       Time  \n",
       "2  23:13:02  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mostInteractedLastMonth\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1309034737756000256\n"
     ]
    }
   ],
   "source": [
    "scrapper = sntwitter.TwitterProfileScraper(username)\n",
    "print(id)\n",
    "list1=[]\n",
    "try:\n",
    "        user = scrapper.entity\n",
    "        # declare a username\n",
    "        # for i, tweet in enumerate(scrapper.get_items()):\n",
    "        list1.append([user.username, user.id, user.displayname,\n",
    "                     user.renderedDescription, user.verified, user.created,\n",
    "                     user.followersCount, user.friendsCount, user.statusesCount,\n",
    "                     user.favouritesCount, user.listedCount, user.mediaCount, user.location,\n",
    "                     user.protected, user.link, user.profileImageUrl])\n",
    "          # break\n",
    "    # tweets loop\n",
    "\n",
    "    # twwts df\n",
    "    # calc\n",
    "    # uuser_df\n",
    "\n",
    "except:\n",
    "        print('fail')\n",
    "\n",
    "user_df = pd.DataFrame(list1, columns=['username', 'id', 'displayname',\n",
    "                                          'renderedDescription', 'verified', 'created',\n",
    "                                          'followersCount', 'friendsCount', 'statusesCount',\n",
    "                                          'favouritesCount', 'listedCount', 'mediaCount', 'location',\n",
    "                                          'protected', 'link', 'profileImageUrl'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "to_bytes() missing required argument 'length' (pos 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [221], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m TweetTimeline\n\u001b[1;32m     12\u001b[0m userDict[\u001b[39m'\u001b[39m\u001b[39mTweetTimeline\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m TweetTimeline\n\u001b[0;32m---> 13\u001b[0m userDict\u001b[39m.\u001b[39;49m__sizeof__()\u001b[39m.\u001b[39;49mto_bytes()\n",
      "\u001b[0;31mTypeError\u001b[0m: to_bytes() missing required argument 'length' (pos 1)"
     ]
    }
   ],
   "source": [
    "SourceList=user_tweets_df['Source'].unique().tolist()\n",
    "user_df['sources'] = [SourceList]\n",
    "userDict = user_df.to_dict('records')[0]\n",
    "LastYearDict = mostInteractedLastYear.to_dict('records')[0]\n",
    "LastWeekDict = mostInteractedLastWeek.to_dict('records')[0]\n",
    "LastMonthDict = mostInteractedLastMonth.to_dict('records')[0]\n",
    "userDict['mostInteractedLastMonth'] = LastMonthDict\n",
    "userDict['mostInteractedLastWeek'] = LastWeekDict\n",
    "userDict['mostInteractedLastYear'] = LastYearDict\n",
    "TweetTimeline=user_tweets_df['DateTime'].to_list()\n",
    "TweetTimeline\n",
    "userDict['TweetTimeline'] = TweetTimeline\n",
    "userDict\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
