{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import snscrape.modules.twitter as sntwitter\n",
        "import pandas as pd\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "hashtag = \"SupremeCourt\"\n",
        "num_tweets = 20\n",
        "\n",
        "# TwitterHashtagScraper\n",
        "# scrapper = sntwitter.TwitterSearchScraper(keyword)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tweets_list = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i, tweet in enumerate(sntwitter.TwitterSearchScraper(hashtag + ' lang:en').get_items()):\n",
        "    if i >= num_tweets:\n",
        "        break\n",
        "    tweets_list.append([tweet.id, tweet.conversationId, tweet.date, tweet.user.id, tweet.user.username, \n",
        "                        tweet.user.displayname, tweet.place, tweet.rawContent, tweet.lang, tweet.mentionedUsers,\n",
        "                       tweet.links, tweet.media, tweet.replyCount, tweet.retweetCount, \n",
        "                       tweet.likeCount, tweet.hashtags, tweet.cashtags, tweet.source, tweet.retweetedTweet, \n",
        "                       tweet.quotedTweet, tweet.inReplyToUser,tweet.inReplyToTweetId, tweet.viewCount])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tweets_df = pd.DataFrame(tweets_list, columns=['id', 'conversation_id', 'date','user_id', 'username', \n",
        "                                               'name', 'place', 'tweet', 'language', 'mentions',\n",
        "                                               'urls', 'photos', 'replies_count', 'retweets_count', \n",
        "                                               'likes_count','hashtags', 'cashtags', 'source', 'retweet', \n",
        "                                               'quote_url','reply_to', 'reply_to_id','view_count'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tweets_df.to_csv('custom_twitter_trend_dataset.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df2 = pd.read_csv('./custom_twitter_trend_dataset.csv')\n",
        "# df2['photos']\n",
        "# total_tweets = df2['photos'].sum()\n",
        "# print(total_tweets)\n",
        "\n",
        "non_media_tweets = df2['photos'].isnull().sum()\n",
        "media_tweets = num_tweets-non_media_tweets\n",
        "\n",
        "max_likedtweets_indexes = df2.nlargest(num_tweets, 'likes_count')[\n",
        "    'likes_count'].index.tolist()\n",
        "\n",
        "max_liked_tweets = df2.loc[max_likedtweets_indexes, 'tweet'].tolist()\n",
        "\n",
        "max_retweets_count_indexes = df2.nlargest(num_tweets, 'retweets_count')[\n",
        "    'likes_count'].index.tolist()\n",
        "\n",
        "max_retweets_tweets = df2.loc[max_retweets_count_indexes, 'tweet'].tolist()\n",
        "\n",
        "df2['media_tweets'] = media_tweets\n",
        "df2['text_tweets'] = non_media_tweets\n",
        "\n",
        "df2['number_max_liked_tweets'] = max_likedtweets_indexes\n",
        "df2['max_liked_tweets'] = max_liked_tweets\n",
        "\n",
        "df2['number_max_retweets_tweets'] = max_retweets_count_indexes\n",
        "df2['max_retweets_tweets'] = max_retweets_tweets\n",
        "\n",
        "check_bot_human = 'bot/human' # 0 - 1\n",
        "\n",
        "df2['check_bot_human'] = check_bot_human\n",
        "\n",
        "unique_users = df2['username'].nunique()\n",
        "\n",
        "df2['unique_participants'] = unique_users\n",
        "\n",
        "unique_users\n",
        "# df2.columns\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from joblib import dump, load\n",
        "from textblob import TextBlob\n",
        "\n",
        "human_list = []\n",
        "bot_list = []\n",
        "\n",
        "def botRecognition(twitter_username):\n",
        "\n",
        "    tweets_list = []\n",
        "    scrapper = sntwitter.TwitterProfileScraper(twitter_username)\n",
        "    user = scrapper.entity\n",
        "    try:\n",
        "        if user.profileImageUrl.startswith(\n",
        "                \"https://abs.twimg.com/sticky/default_profile_images/\"):\n",
        "            xdefault_profile_image = 'TRUE'\n",
        "        else:\n",
        "            xdefault_profile_image = 'FALSE'\n",
        "\n",
        "        # # custom logic\n",
        "        if xdefault_profile_image == 'FALSE' or user.profileBannerUrl or user.renderedDescription or user.verified or user.location or user.link:\n",
        "            xdefaultProfile = 'FALSE'\n",
        "        else:\n",
        "            xdefaultProfile = 'TRUE'\n",
        "\n",
        "        tweets_list.append([\n",
        "            user.created,\n",
        "            xdefaultProfile,\n",
        "            xdefault_profile_image,\n",
        "            user.renderedDescription,\n",
        "            user.favouritesCount,\n",
        "            user.followersCount,\n",
        "            user.friendsCount,\n",
        "            # user.geo_enabled,\n",
        "            user.id,\n",
        "            user.location,\n",
        "            user.profileBannerUrl,\n",
        "            user.profileImageUrl,\n",
        "            user.username,\n",
        "            user.statusesCount,\n",
        "            user.verified,\n",
        "            user.statusesCount /\n",
        "            (pd.Timestamp.now().date() - user.created.date()).days,\n",
        "            (pd.Timestamp.now().date() - user.created.date()).days,\n",
        "        ])\n",
        "\n",
        "        user_df = pd.DataFrame(\n",
        "            tweets_list,\n",
        "            columns=[\n",
        "                'created_at',\n",
        "                'default_profile',\n",
        "                'default_profile_image',\n",
        "                'description',\n",
        "                'favourites_count',\n",
        "                'followers_count',\n",
        "                'friends_count',\n",
        "                # 'geo_enabled',\n",
        "                'id',\n",
        "                'location',\n",
        "                'profile_background_image_url',\n",
        "                'profile_image_url',\n",
        "                'screen_name',\n",
        "                'statuses_count',\n",
        "                'verified',\n",
        "                'average_tweets_per_day',\n",
        "                'account_age_days',\n",
        "            ])\n",
        "\n",
        "    except:\n",
        "        dict = {'result': [-1]}\n",
        "        user_df = pd.DataFrame(dict)\n",
        "        return user_df\n",
        "\n",
        "    if (user_df['average_tweets_per_day'][0] < 0.2):\n",
        "        user_df['result'] = 0\n",
        "        return user_df\n",
        "\n",
        "    user_df.verified = user_df.verified.astype('bool')\n",
        "    user_df.verified = user_df.verified.astype(int)\n",
        "    user_df.default_profile = user_df.default_profile.astype('bool')\n",
        "    user_df.default_profile = user_df.default_profile.astype(int)\n",
        "    user_df.default_profile_image = user_df.default_profile_image.astype(\n",
        "        'bool')\n",
        "    user_df.default_profile_image = user_df.default_profile_image.astype(int)\n",
        "\n",
        "    user_df.followers_count = user_df.followers_count.astype(int)\n",
        "    user_df.friends_count = user_df.friends_count.astype(int)\n",
        "    user_df.favourites_count = user_df.favourites_count.astype(int)\n",
        "    user_df.statuses_count = user_df.statuses_count.astype(int)\n",
        "\n",
        "    user_df[\"screen_name_len\"] = [len(i) for i in user_df[\"screen_name\"]]\n",
        "    user_df[\"bot_is_substr\"] = [int('bot' in i.lower())\n",
        "                                for i in user_df[\"screen_name\"]]\n",
        "    user_df[\"bot_in_des\"] = [int('bot' in str(i).lower())\n",
        "                            for i in user_df['description']]\n",
        "\n",
        "    # Getting the ages in years from created_at\n",
        "    ages = []\n",
        "    for i in user_df[\"created_at\"]:\n",
        "        year = i.year\n",
        "        age = 17-year\n",
        "        ages.append(age)\n",
        "    user_df[\"age\"] = ages\n",
        "\n",
        "    descriptions = [TextBlob(str(txt)) for txt in user_df['description']]\n",
        "\n",
        "    # Creating lists of the polarity and the descriptions\n",
        "    desc_pol = [blob.sentiment.polarity for blob in descriptions]\n",
        "    desc_subj = [blob.sentiment.subjectivity for blob in descriptions]\n",
        "\n",
        "    # Turning them into features\n",
        "    user_df[\"desc_pol\"] = desc_pol\n",
        "    user_df[\"desc_subj\"] = desc_subj\n",
        "    features = ['age', 'followers_count', 'friends_count', 'favourites_count', 'statuses_count',\n",
        "                'screen_name_len', 'bot_in_des', 'bot_is_substr', 'desc_pol', 'desc_subj']\n",
        "\n",
        "    # clf=load('randomforest.joblib')\n",
        "    # features = ['age','followers_count','friends_count','favourites_count','statuses_count','screen_name_len','bot_in_des','bot_is_substr', 'desc_pol','desc_subj']\n",
        "    # pre=clf.predict(user_df[features])\n",
        "    # print(pre)\n",
        "\n",
        "    # //better\n",
        "    clf = load('randomforest1.joblib')\n",
        "\n",
        "    pre = clf.predict(user_df[features])\n",
        "    # print(pre)\n",
        "    user_df['result'] = pre\n",
        "\n",
        "    temp = user_df['result'][0]\n",
        "\n",
        "    # print(temp)\n",
        "\n",
        "    \n",
        "    if temp == 0:\n",
        "        human_list.append(twitter_username)\n",
        "\n",
        "    \n",
        "    # df2[selected_columns].to_csv('ide_bot.csv', index=False)\n",
        "    # df2[selected_columns].to_csv('ide_human.csv', index=False)\n",
        "\n",
        "    if temp == 1:\n",
        "        bot_list.append(twitter_username)\n",
        "\n",
        "    return user_df\n",
        "\n",
        "\n",
        "for twitter_username in df2['username']:\n",
        "    botRecognition(twitter_username)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "human_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bot_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_bot = pd.DataFrame(bot_list, columns=['username'])\n",
        "df_bot.to_csv('ide_bot.csv', index=False)\n",
        "\n",
        "df_human = pd.DataFrame(human_list, columns=['username'])\n",
        "df_human.to_csv('ide_human.csv', index=False)\n",
        "\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "\n",
        "# value = (df2.iloc[i]['username'])\n",
        "# if (df2['username'].isin([value]).any()):\n",
        "#     count1 = count1 + 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "df3 = pd.read_csv(\"./ide_bot.csv\")\n",
        "df4 = pd.read_csv(\"./ide_human.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# # checking tweet made by bot accounts\n",
        "# count = 0\n",
        "# for i in range(num_tweets):\n",
        "#     username = df2.loc[i, 'username']\n",
        "#     value = df2.loc[i, 'check_bot_human']\n",
        "\n",
        "#     # print(f\"{username, value}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# checking tweets made by bot accounts\n",
        "counttwb = 0\n",
        "for i in range(num_tweets):\n",
        "   value = (df2['username'][i])\n",
        "   if (df3['username'].isin([value]).any()):\n",
        "       counttwb = counttwb+1\n",
        "\n",
        "df2['tweets_by_bots'] = counttwb\n",
        "print('no of tweet made by bot overall', counttwb)\n",
        "\n",
        "# checking tweets made by human accounts\n",
        "counttwh = 0\n",
        "for i in range(num_tweets):\n",
        "   value = (df2['username'][i])\n",
        "   if (df4['username'].isin([value]).any()):\n",
        "       counttwh = counttwh+1\n",
        "\n",
        "df2['tweets_by_human'] = counttwh\n",
        "print('no of tweet made by human overall', counttwh)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "# filter dataframe by time\n",
        "df2['date'] = pd.to_datetime(df2['date'], format='%Y-%m-%d %H:%M:%S%z')\n",
        "df2 = df2.sort_values(by='date')\n",
        "\n",
        "\n",
        "# access time filtered datafram index by index\n",
        "for i in range(1):\n",
        "    df2.iloc[i]['username']\n",
        "    df2.iloc[i]['date']\n",
        "    # print(df2.iloc[i]['username'])\n",
        "    # print(df2.iloc[i]['date'])\n",
        "\n",
        "# checking ratio of bot in first 1000\n",
        "count1 = 0\n",
        "for i in range(num_tweets):\n",
        "   value = (df2.iloc[i]['username'])\n",
        "   if (df3['username'].isin([value]).any()):\n",
        "       count1 = count1 + 1\n",
        "\n",
        "df2['bot_tweets_in_data'] = count1\n",
        "\n",
        "# checking ratio of human in first 1000\n",
        "count1 = 0\n",
        "for i in range(num_tweets):\n",
        "   value = (df2.iloc[i]['username'])\n",
        "   if (df3['username'].isin([value]).any()):\n",
        "       count1 = count1 + 1\n",
        "\n",
        "df2['bot_tweets_in_data'] = count1\n",
        "# print('bot number of df2 in first 1000 tweets', count1)\n",
        "\n",
        "\n",
        "#\n",
        "\n",
        "\n",
        "# finding df2 in first 2 hour\n",
        "# print('start time is ')\n",
        "hcount = 0\n",
        "start_time = pd.to_datetime(df2.iloc[0]['date'], format='%H:%M:%S')\n",
        "# print('start time is ', start_time)\n",
        "\n",
        "end_time = start_time + pd.Timedelta(hours=2)\n",
        "# print('end time is ', end_time)\n",
        "\n",
        "\n",
        "hcount = len(df2[(df2['date'] >= start_time) & (df2['date'] < end_time)])\n",
        "\n",
        "# df2['tweets'] = count1\n",
        "# print('df2 in first 2 hours is :', hcount)\n",
        "\n",
        "# # alternative finding df2 in first 2 hour\n",
        "# for i in range (3000):\n",
        "#     if(df2.iloc[i]['date']< end_time):\n",
        "#         hcount = hcount+1\n",
        "\n",
        "\n",
        "# print('df2 in first 2 hours is :',hcount);\n",
        "\n",
        "\n",
        "# unique account participation\n",
        "unique_account = df2['username'].nunique()\n",
        "\n",
        "df2['unique_acc_partic'] = unique_account\n",
        "# print(\"Unique account participation is :\", unique_account)\n",
        "\n",
        "# unique message in trend\n",
        "unique_tweet = df2['tweet'].nunique()\n",
        "df2['unique_twt_partic'] = unique_tweet\n",
        "# print('unique df2 is :', unique_tweet)\n",
        "\n",
        "# finding velocity of trend\n",
        "\n",
        "# print('')\n",
        "# print('Finding Acceleration.')\n",
        "start_time = pd.to_datetime(df2.iloc[0]['date'], format='%Y-%m-%d %H:%M:%S%z')\n",
        "# print('start time is ', start_time)\n",
        "i = 1\n",
        "acceleration_list = []\n",
        "hour_list = []\n",
        "count_list = []\n",
        "merge_list = []\n",
        "for i in range(6):\n",
        "\n",
        "    end_time = start_time + pd.Timedelta(hours=1)\n",
        "    # print('end time is ', end_time)\n",
        "\n",
        "    hcount = len(df2[(df2['date'] >= start_time) & (df2['date'] < end_time)])\n",
        "    # Create a boolean mask for df2s in the time range\n",
        "    time_mask = (df2['date'] >= start_time) & (df2['date'] < end_time)\n",
        "\n",
        "    # Select the user IDs of df2s in the time range\n",
        "    users_in_range = df2.loc[time_mask, 'username']\n",
        "\n",
        "    # Count the number of bot users in the time range\n",
        "    num_bot_users = users_in_range.isin(df3['username']).sum()\n",
        "    # print('num of bot user ', num_bot_users)\n",
        "    # print(\"df2 in first \" + str(i+1) + \" hours is :\", hcount)\n",
        "    count_list.append(hcount)\n",
        "    hour_list.append(i+1)\n",
        "    if (i == 0):\n",
        "        acceleration_list.append(hcount)\n",
        "    else:\n",
        "        acceleration_list.append(hcount - acceleration_list[i-1])\n",
        "    start_time = end_time\n",
        "\n",
        "# print(acceleration_list)\n",
        "# print(count_list)\n",
        "\n",
        "#\n",
        "# #\n",
        "# #\n",
        "# #\n",
        "# #\n",
        "# df2['hour_twt_by_bot_hr'].fillna(0, inplace=True)\n",
        "# df2['hour_twt_by_bot_hr'] = hour_list\n",
        "\n",
        "# df2['count_twt_by_bot_hr'].fillna(0, inplace=True)\n",
        "# df2['count_twt_by_bot_hr'] = count_list\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_dummy = pd.read_csv('./tweets_24_notendencias_raw.csv', nrows=1)\n",
        "# print(df_dummy.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df = pd.read_csv('./custom_twitter_trend_dataset.csv')\n",
        "# print(df2.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_dummy.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv('./custom_twitter_trend_dataset.csv')\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "json_object = df2.to_json()\n",
        "\n",
        "# print(json_object)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# jsonobjc = json.dumps(json_object)\n",
        "# data_folder = Path(\"\")\n",
        "# file_to_open = data_folder / \"jsonobjtrend.json\"\n",
        "# file = open(file_to_open, \"w\")\n",
        "# file.write(jsonobjc)\n",
        "# file.close()\n",
        "\n",
        "if (json_object):\n",
        "    # Writing to json\n",
        "    data_folder = Path(\"\")\n",
        "    file_to_open = data_folder / \"jsonobjtrend.json\"\n",
        "    file = open(file_to_open, \"w\")\n",
        "    file.write(json_object)\n",
        "    file.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# unique accounts\n",
        "# unique messages\n",
        "# bot list by hour\n",
        "# human list by hour\n",
        "# ok."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
