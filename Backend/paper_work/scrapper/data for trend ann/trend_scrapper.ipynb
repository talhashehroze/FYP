{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "import snscrape.modules.twitter as sntwitter\n",
        "import pandas as pd\n",
        "from joblib import dump, load\n",
        "from textblob import TextBlob\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "hashtag = \"SupremeCourt\"\n",
        "num_tweets = 10\n",
        "\n",
        "# TwitterHashtagScraper\n",
        "# scrapper = sntwitter.TwitterSearchScraper(keyword)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "tweets_list = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i, tweet in enumerate(sntwitter.TwitterSearchScraper(hashtag + ' lang:en').get_items()):\n",
        "        if i >= num_tweets:\n",
        "            break\n",
        "        tweets_list.append([tweet.id, tweet.conversationId, tweet.date, tweet.user.id, tweet.user.username,\n",
        "                            tweet.user.displayname, tweet.place, tweet.rawContent, tweet.lang, tweet.mentionedUsers,\n",
        "                            tweet.links, tweet.media, tweet.replyCount, tweet.retweetCount,\n",
        "                            tweet.likeCount, tweet.hashtags, tweet.cashtags, tweet.source, tweet.retweetedTweet,\n",
        "                            tweet.quotedTweet, tweet.inReplyToUser, tweet.inReplyToTweetId, tweet.viewCount])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "tweets_df = pd.DataFrame(tweets_list, columns=['id', 'conversation_id', 'date','user_id', 'username', \n",
        "                                               'name', 'place', 'tweet', 'language', 'mentions',\n",
        "                                               'urls', 'photos', 'replies_count', 'retweets_count', \n",
        "                                               'likes_count','hashtags', 'cashtags', 'source', 'retweet', \n",
        "                                               'quote_url','reply_to', 'reply_to_id','view_count'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "tweets_df.to_csv('custom_twitter_trend_dataset.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df2 = pd.read_csv('./custom_twitter_trend_dataset.csv')\n",
        "# df2['photos']\n",
        "# total_tweets = df2['photos'].sum()\n",
        "# print(total_tweets)\n",
        "\n",
        "non_media_tweets = df2['photos'].isnull().sum()\n",
        "media_tweets = num_tweets-non_media_tweets\n",
        "\n",
        "max_likedtweets_indexes = df2.nlargest(num_tweets, 'likes_count')[\n",
        "    'likes_count'].index.tolist()\n",
        "\n",
        "tweets = []\n",
        "likes_count = []\n",
        "usernames = []\n",
        "\n",
        "for index in max_likedtweets_indexes:\n",
        "    tweet = df2.loc[index, 'tweet']\n",
        "    likes = df2.loc[index, 'likes_count']\n",
        "    username = df2.loc[index, 'username']\n",
        "\n",
        "    tweets.append(tweet)\n",
        "    likes_count.append(likes)\n",
        "    usernames.append(username)\n",
        "\n",
        "df2['max_liked_tweets'] = tweets\n",
        "df2['number_max_liked_tweets'] = likes_count\n",
        "df2['max_liked_tweet_username'] = usernames\n",
        "\n",
        "max_retweets_count_indexes = df2.nlargest(num_tweets, 'retweets_count')[\n",
        "    'likes_count'].index.tolist()\n",
        "\n",
        "tweet_list = []\n",
        "retweets_count_list = []\n",
        "username_list = []\n",
        "\n",
        "for index in max_retweets_count_indexes:\n",
        "    tweet = df2.at[index, 'tweet']\n",
        "    retweets_count = df2.at[index, 'retweets_count']\n",
        "    username = df2.at[index, 'username']\n",
        "    tweet_list.append(tweet)\n",
        "    retweets_count_list.append(retweets_count)\n",
        "    username_list.append(username)\n",
        "\n",
        "# create new columns in df2\n",
        "df2['max_retweets_tweets'] = tweet_list\n",
        "df2['number_max_retweets_tweets'] = retweets_count_list\n",
        "df2['max_retweets_username'] = username_list\n",
        "\n",
        "\n",
        "df2['media_tweets'] = media_tweets\n",
        "df2['text_tweets'] = non_media_tweets\n",
        "\n",
        "\n",
        "# check_bot_human = 'bot/human'  # 0 - 1\n",
        "\n",
        "# df2['check_bot_human'] = check_bot_human\n",
        "\n",
        "unique_users = df2['username'].nunique()\n",
        "\n",
        "df2['unique_participants'] = unique_users\n",
        "\n",
        "unique_users\n",
        "# df2.columns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\talhaahmad\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.23.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "C:\\Users\\talhaahmad\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.23.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "C:\\Users\\talhaahmad\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n",
            "C:\\Users\\talhaahmad\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.23.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "C:\\Users\\talhaahmad\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.23.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "C:\\Users\\talhaahmad\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n",
            "C:\\Users\\talhaahmad\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.23.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "C:\\Users\\talhaahmad\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.23.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "C:\\Users\\talhaahmad\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n",
            "C:\\Users\\talhaahmad\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.23.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "C:\\Users\\talhaahmad\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.23.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "C:\\Users\\talhaahmad\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n",
            "C:\\Users\\talhaahmad\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.23.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "C:\\Users\\talhaahmad\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.23.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "C:\\Users\\talhaahmad\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n",
            "C:\\Users\\talhaahmad\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.23.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "C:\\Users\\talhaahmad\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.23.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "C:\\Users\\talhaahmad\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n",
            "C:\\Users\\talhaahmad\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.23.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "C:\\Users\\talhaahmad\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.23.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "C:\\Users\\talhaahmad\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n",
            "C:\\Users\\talhaahmad\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.23.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "C:\\Users\\talhaahmad\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.23.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "C:\\Users\\talhaahmad\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n",
            "C:\\Users\\talhaahmad\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.23.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "C:\\Users\\talhaahmad\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.23.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "C:\\Users\\talhaahmad\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n",
            "C:\\Users\\talhaahmad\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.23.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "C:\\Users\\talhaahmad\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:318: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.23.2 when using version 1.2.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
            "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
            "  warnings.warn(\n",
            "C:\\Users\\talhaahmad\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:432: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "human_list = []\n",
        "bot_list = []\n",
        "\n",
        "def botRecognition(twitter_username):\n",
        "\n",
        "    tweets_list = []\n",
        "    scrapper = sntwitter.TwitterProfileScraper(twitter_username)\n",
        "    user = scrapper.entity\n",
        "    try:\n",
        "        if user.profileImageUrl.startswith(\n",
        "                \"https://abs.twimg.com/sticky/default_profile_images/\"):\n",
        "            xdefault_profile_image = 'TRUE'\n",
        "        else:\n",
        "            xdefault_profile_image = 'FALSE'\n",
        "\n",
        "        # # custom logic\n",
        "        if xdefault_profile_image == 'FALSE' or user.profileBannerUrl or user.renderedDescription or user.verified or user.location or user.link:\n",
        "            xdefaultProfile = 'FALSE'\n",
        "        else:\n",
        "            xdefaultProfile = 'TRUE'\n",
        "\n",
        "        tweets_list.append([\n",
        "            user.created,\n",
        "            xdefaultProfile,\n",
        "            xdefault_profile_image,\n",
        "            user.renderedDescription,\n",
        "            user.favouritesCount,\n",
        "            user.followersCount,\n",
        "            user.friendsCount,\n",
        "            # user.geo_enabled,\n",
        "            user.id,\n",
        "            user.location,\n",
        "            user.profileBannerUrl,\n",
        "            user.profileImageUrl,\n",
        "            user.username,\n",
        "            user.statusesCount,\n",
        "            user.verified,\n",
        "            user.statusesCount /\n",
        "            (pd.Timestamp.now().date() - user.created.date()).days,\n",
        "            (pd.Timestamp.now().date() - user.created.date()).days,\n",
        "        ])\n",
        "\n",
        "        user_df = pd.DataFrame(\n",
        "            tweets_list,\n",
        "            columns=[\n",
        "                'created_at',\n",
        "                'default_profile',\n",
        "                'default_profile_image',\n",
        "                'description',\n",
        "                'favourites_count',\n",
        "                'followers_count',\n",
        "                'friends_count',\n",
        "                # 'geo_enabled',\n",
        "                'id',\n",
        "                'location',\n",
        "                'profile_background_image_url',\n",
        "                'profile_image_url',\n",
        "                'screen_name',\n",
        "                'statuses_count',\n",
        "                'verified',\n",
        "                'average_tweets_per_day',\n",
        "                'account_age_days',\n",
        "            ])\n",
        "\n",
        "    except:\n",
        "        dict = {'result': [-1]}\n",
        "        user_df = pd.DataFrame(dict)\n",
        "        return user_df\n",
        "\n",
        "    if (user_df['average_tweets_per_day'][0] < 0.2):\n",
        "        user_df['result'] = 0\n",
        "        return user_df\n",
        "\n",
        "    user_df.verified = user_df.verified.astype('bool')\n",
        "    user_df.verified = user_df.verified.astype(int)\n",
        "    user_df.default_profile = user_df.default_profile.astype('bool')\n",
        "    user_df.default_profile = user_df.default_profile.astype(int)\n",
        "    user_df.default_profile_image = user_df.default_profile_image.astype(\n",
        "        'bool')\n",
        "    user_df.default_profile_image = user_df.default_profile_image.astype(\n",
        "        int)\n",
        "\n",
        "    user_df.followers_count = user_df.followers_count.astype(int)\n",
        "    user_df.friends_count = user_df.friends_count.astype(int)\n",
        "    user_df.favourites_count = user_df.favourites_count.astype(int)\n",
        "    user_df.statuses_count = user_df.statuses_count.astype(int)\n",
        "\n",
        "    user_df[\"screen_name_len\"] = [len(i) for i in user_df[\"screen_name\"]]\n",
        "    user_df[\"bot_is_substr\"] = [int('bot' in i.lower())\n",
        "                                for i in user_df[\"screen_name\"]]\n",
        "    user_df[\"bot_in_des\"] = [int('bot' in str(i).lower())\n",
        "                                for i in user_df['description']]\n",
        "\n",
        "    # Getting the ages in years from created_at\n",
        "    ages = []\n",
        "    for i in user_df[\"created_at\"]:\n",
        "        year = i.year\n",
        "        age = 17-year\n",
        "        ages.append(age)\n",
        "    user_df[\"age\"] = ages\n",
        "\n",
        "    descriptions = [TextBlob(str(txt)) for txt in user_df['description']]\n",
        "\n",
        "    # Creating lists of the polarity and the descriptions\n",
        "    desc_pol = [blob.sentiment.polarity for blob in descriptions]\n",
        "    desc_subj = [blob.sentiment.subjectivity for blob in descriptions]\n",
        "\n",
        "    # Turning them into features\n",
        "    user_df[\"desc_pol\"] = desc_pol\n",
        "    user_df[\"desc_subj\"] = desc_subj\n",
        "    features = ['age', 'followers_count', 'friends_count', 'favourites_count', 'statuses_count',\n",
        "                'screen_name_len', 'bot_in_des', 'bot_is_substr', 'desc_pol', 'desc_subj']\n",
        "\n",
        "    # clf=load('randomforest.joblib')\n",
        "    # features = ['age','followers_count','friends_count','favourites_count','statuses_count','screen_name_len','bot_in_des','bot_is_substr', 'desc_pol','desc_subj']\n",
        "    # pre=clf.predict(user_df[features])\n",
        "    # print(pre)\n",
        "\n",
        "    # //better\n",
        "    clf = load('randomforest1.joblib')\n",
        "\n",
        "    pre = clf.predict(user_df[features])\n",
        "    # print(pre)\n",
        "    user_df['result'] = pre\n",
        "\n",
        "    temp = user_df['result'][0]\n",
        "\n",
        "    # print(temp)\n",
        "\n",
        "    if temp == 0:\n",
        "        human_list.append(twitter_username)\n",
        "\n",
        "    # df2[selected_columns].to_csv('ide_bot.csv', index=False)\n",
        "    # df2[selected_columns].to_csv('ide_human.csv', index=False)\n",
        "\n",
        "    if temp == 1:\n",
        "        bot_list.append(twitter_username)\n",
        "\n",
        "    return user_df\n",
        "\n",
        "for twitter_username in df2['username']:\n",
        "    botRecognition(twitter_username)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "human_list\n",
        "unique_human_count = set(human_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "bot_list\n",
        "unique_bots_count = set(bot_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_bot = pd.DataFrame(bot_list, columns=['username'])\n",
        "df_bot.to_csv('ide_bot.csv', index=False)\n",
        "\n",
        "df_human = pd.DataFrame(human_list, columns=['username'])\n",
        "df_human.to_csv('ide_human.csv', index=False)\n",
        "\n",
        "df_bot_unique = pd.DataFrame(unique_bots_count, columns=['username'])\n",
        "df_bot_unique.to_csv('ide_bot_unique.csv', index=False)\n",
        "\n",
        "df_human_unique = pd.DataFrame(unique_human_count, columns=['username'])\n",
        "df_human_unique.to_csv('ide_human_unique.csv', index=False)\n",
        "\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "#\n",
        "\n",
        "# value = (df2.iloc[i]['username'])\n",
        "# if (df2['username'].isin([value]).any()):\n",
        "#     count1 = count1 + 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "df3 = pd.read_csv(\"./ide_bot.csv\")\n",
        "df4 = pd.read_csv(\"./ide_human.csv\")\n",
        "\n",
        "df7 = pd.read_csv(\"./ide_bot_unique.csv\")\n",
        "df8 = pd.read_csv(\"./ide_human_unique.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "# # checking tweet made by bot accounts\n",
        "# count = 0\n",
        "# for i in range(num_tweets):\n",
        "#     username = df2.loc[i, 'username']\n",
        "#     value = df2.loc[i, 'check_bot_human']\n",
        "\n",
        "#     # print(f\"{username, value}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "no of bot in data 6\n",
            "no of human in data 4\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# checking tweets made by bot accounts\n",
        "counttwb = 0\n",
        "for i in range(num_tweets):\n",
        "   value = (df2['username'][i])\n",
        "   if (df7['username'].isin([value]).any()):\n",
        "       counttwb = counttwb+1\n",
        "\n",
        "df2['no_bots_in_data'] = counttwb\n",
        "print('no of bot in data', counttwb)\n",
        "\n",
        "# checking tweets made by human accounts\n",
        "counttwh = 0\n",
        "for i in range(num_tweets):\n",
        "   value = (df2['username'][i])\n",
        "   if (df8['username'].isin([value]).any()):\n",
        "       counttwh = counttwh+1\n",
        "\n",
        "df2['analyzed_tweets'] = num_tweets\n",
        "df2['trend_name']= hashtag\n",
        "df2['no_humans_in_data'] = counttwh\n",
        "print('no of human in data', counttwh)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "no of tweet made by bot overall 6\n",
            "no of tweet made by human overall 4\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# checking tweets made by bot accounts\n",
        "counttwb = 0\n",
        "for i in range(num_tweets):\n",
        "   value = (df2['username'][i])\n",
        "   if (df3['username'].isin([value]).any()):\n",
        "       counttwb = counttwb+1\n",
        "\n",
        "df2['tweets_by_bots'] = counttwb\n",
        "print('no of tweet made by bot overall', counttwb)\n",
        "\n",
        "# checking tweets made by human accounts\n",
        "counttwh = 0\n",
        "for i in range(num_tweets):\n",
        "   value = (df2['username'][i])\n",
        "   if (df4['username'].isin([value]).any()):\n",
        "       counttwh = counttwh+1\n",
        "\n",
        "df2['tweets_by_human'] = counttwh\n",
        "print('no of tweet made by human overall', counttwh)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "# filter dataframe by time\n",
        "df2['date'] = pd.to_datetime(df2['date'], format='%Y-%m-%d %H:%M:%S%z')\n",
        "df2 = df2.sort_values(by='date')\n",
        "\n",
        "\n",
        "# access time filtered datafram index by index\n",
        "for i in range(1):\n",
        "    df2.iloc[i]['username']\n",
        "    df2.iloc[i]['date']\n",
        "    # print(df2.iloc[i]['username'])\n",
        "    # print(df2.iloc[i]['date'])\n",
        "\n",
        "# checking ratio of bot in first 1000\n",
        "count1 = 0\n",
        "for i in range(num_tweets):\n",
        "   value = (df2.iloc[i]['username'])\n",
        "   if (df3['username'].isin([value]).any()):\n",
        "       count1 = count1 + 1\n",
        "\n",
        "# df2['bot_tweets_in_data'] = count1\n",
        "\n",
        "# checking ratio of human in first 1000\n",
        "count2 = 0\n",
        "for i in range(num_tweets):\n",
        "   value = (df2.iloc[i]['username'])\n",
        "   if (df3['username'].isin([value]).any()):\n",
        "       count2 = count2 + 1\n",
        "\n",
        "# df2['bot_tweets_in_data'] = count1\n",
        "# print('bot number of df2 in first 1000 tweets', count1)\n",
        "\n",
        "\n",
        "#\n",
        "\n",
        "\n",
        "# finding df2 in first 2 hour\n",
        "# print('start time is ')\n",
        "hcount = 0\n",
        "start_time = pd.to_datetime(df2.iloc[0]['date'], format='%H:%M:%S')\n",
        "# print('start time is ', start_time)\n",
        "\n",
        "end_time = start_time + pd.Timedelta(hours=2)\n",
        "# print('end time is ', end_time)\n",
        "\n",
        "\n",
        "hcount = len(df2[(df2['date'] >= start_time) & (df2['date'] < end_time)])\n",
        "\n",
        "# df2['tweets'] = count1\n",
        "# print('df2 in first 2 hours is :', hcount)\n",
        "\n",
        "# # alternative finding df2 in first 2 hour\n",
        "# for i in range (3000):\n",
        "#     if(df2.iloc[i]['date']< end_time):\n",
        "#         hcount = hcount+1\n",
        "\n",
        "\n",
        "# print('df2 in first 2 hours is :',hcount);\n",
        "\n",
        "\n",
        "# unique account participation\n",
        "unique_account = df2['username'].nunique()\n",
        "\n",
        "df2['unique_acc_partic'] = unique_account\n",
        "# print(\"Unique account participation is :\", unique_account)\n",
        "\n",
        "# unique message in trend\n",
        "unique_tweet = df2['tweet'].nunique()\n",
        "df2['unique_twt_partic'] = unique_tweet\n",
        "# print('unique df2 is :', unique_tweet)\n",
        "\n",
        "# finding velocity of trend\n",
        "\n",
        "# print('')\n",
        "# print('Finding Acceleration.')\n",
        "start_time = pd.to_datetime(df2.iloc[0]['date'], format='%Y-%m-%d %H:%M:%S%z')\n",
        "# print('start time is ', start_time)\n",
        "i = 1\n",
        "acceleration_list = []\n",
        "hour_list = []\n",
        "count_list = []\n",
        "merge_list = []\n",
        "for i in range(6):\n",
        "\n",
        "    end_time = start_time + pd.Timedelta(hours=1)\n",
        "    # print('end time is ', end_time)\n",
        "\n",
        "    hcount = len(df2[(df2['date'] >= start_time) & (df2['date'] < end_time)])\n",
        "    # Create a boolean mask for df2s in the time range\n",
        "    time_mask = (df2['date'] >= start_time) & (df2['date'] < end_time)\n",
        "\n",
        "    # Select the user IDs of df2s in the time range\n",
        "    users_in_range = df2.loc[time_mask, 'username']\n",
        "\n",
        "    # Count the number of bot users in the time range\n",
        "    num_bot_users = users_in_range.isin(df3['username']).sum()\n",
        "    # print('num of bot user ', num_bot_users)\n",
        "    # print(\"df2 in first \" + str(i+1) + \" hours is :\", hcount)\n",
        "    count_list.append(hcount)\n",
        "    hour_list.append(i+1)\n",
        "    if (i == 0):\n",
        "        acceleration_list.append(hcount)\n",
        "    else:\n",
        "        acceleration_list.append(hcount - acceleration_list[i-1])\n",
        "    start_time = end_time\n",
        "\n",
        "# print(acceleration_list)\n",
        "# print(count_list)\n",
        "\n",
        "#\n",
        "# #\n",
        "# #\n",
        "# #\n",
        "# #\n",
        "# df2['hour_twt_by_bot_hr'].fillna(0, inplace=True)\n",
        "# df2['hour_twt_by_bot_hr'] = hour_list\n",
        "\n",
        "# df2['count_twt_by_bot_hr'].fillna(0, inplace=True)\n",
        "# df2['count_twt_by_bot_hr'] = count_list\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_dummy = pd.read_csv('./tweets_24_notendencias_raw.csv', nrows=1)\n",
        "# print(df_dummy.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df = pd.read_csv('./custom_twitter_trend_dataset.csv')\n",
        "# print(df2.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "# df_dummy.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>conversation_id</th>\n",
              "      <th>date</th>\n",
              "      <th>user_id</th>\n",
              "      <th>username</th>\n",
              "      <th>name</th>\n",
              "      <th>place</th>\n",
              "      <th>tweet</th>\n",
              "      <th>language</th>\n",
              "      <th>mentions</th>\n",
              "      <th>...</th>\n",
              "      <th>retweets_count</th>\n",
              "      <th>likes_count</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>cashtags</th>\n",
              "      <th>source</th>\n",
              "      <th>retweet</th>\n",
              "      <th>quote_url</th>\n",
              "      <th>reply_to</th>\n",
              "      <th>reply_to_id</th>\n",
              "      <th>view_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1641660343763042304</td>\n",
              "      <td>1641582374411550720</td>\n",
              "      <td>2023-03-31 04:35:01+00:00</td>\n",
              "      <td>323397650</td>\n",
              "      <td>DirtyHardMoney</td>\n",
              "      <td>Dimas Garcia</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@GlennYoungkin Wait what...? Like weaponizing ...</td>\n",
              "      <td>en</td>\n",
              "      <td>[User(username='GlennYoungkin', id=12760483305...</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://twitter.com/GlennYoungkin</td>\n",
              "      <td>1.641582e+18</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1641660336733585408</td>\n",
              "      <td>1641470562013937667</td>\n",
              "      <td>2023-03-31 04:34:59+00:00</td>\n",
              "      <td>157959833</td>\n",
              "      <td>Deepali_p</td>\n",
              "      <td>Deepali Prabhu</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@ani30oct It won't be tabled. Every vote bank ...</td>\n",
              "      <td>en</td>\n",
              "      <td>[User(username='ani30oct', id=58516766, displa...</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/android\" ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://twitter.com/ani30oct</td>\n",
              "      <td>1.641659e+18</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1641660299773190145</td>\n",
              "      <td>1641660299773190145</td>\n",
              "      <td>2023-03-31 04:34:50+00:00</td>\n",
              "      <td>991401146</td>\n",
              "      <td>Kerala__</td>\n",
              "      <td>Kerala കേരളം</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ShashiTharoor: 2/2 My 2014 Private Members' Bi...</td>\n",
              "      <td>en</td>\n",
              "      <td>[User(username='INCIndia', id=1153045459, disp...</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;a href=\"https://ifttt.com\" rel=\"nofollow\"&gt;IFT...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1641660289094668289</td>\n",
              "      <td>1641265090191142917</td>\n",
              "      <td>2023-03-31 04:34:48+00:00</td>\n",
              "      <td>450142621</td>\n",
              "      <td>northwestglock</td>\n",
              "      <td>NorthwestGlockman</td>\n",
              "      <td>Place(id='d44cb984bf75455e', fullName='Lake St...</td>\n",
              "      <td>@JeremyRedfernFL The Supreme Court already rul...</td>\n",
              "      <td>en</td>\n",
              "      <td>[User(username='JeremyRedfernFL', id=65995404,...</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;a href=\"http://twitter.com/download/iphone\" r...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://twitter.com/JeremyRedfernFL</td>\n",
              "      <td>1.641265e+18</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1641660284724203521</td>\n",
              "      <td>1641303871963426816</td>\n",
              "      <td>2023-03-31 04:34:47+00:00</td>\n",
              "      <td>1351955339894145024</td>\n",
              "      <td>Beetle25521100</td>\n",
              "      <td>Beetle</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@sardesairajdeep Supreme court is impotent. Th...</td>\n",
              "      <td>en</td>\n",
              "      <td>[User(username='sardesairajdeep', id=56304605,...</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>&lt;a href=\"https://mobile.twitter.com\" rel=\"nofo...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>https://twitter.com/sardesairajdeep</td>\n",
              "      <td>1.641304e+18</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                    id      conversation_id                       date  \\\n",
              "0  1641660343763042304  1641582374411550720  2023-03-31 04:35:01+00:00   \n",
              "1  1641660336733585408  1641470562013937667  2023-03-31 04:34:59+00:00   \n",
              "2  1641660299773190145  1641660299773190145  2023-03-31 04:34:50+00:00   \n",
              "3  1641660289094668289  1641265090191142917  2023-03-31 04:34:48+00:00   \n",
              "4  1641660284724203521  1641303871963426816  2023-03-31 04:34:47+00:00   \n",
              "\n",
              "               user_id        username               name  \\\n",
              "0            323397650  DirtyHardMoney       Dimas Garcia   \n",
              "1            157959833       Deepali_p     Deepali Prabhu   \n",
              "2            991401146        Kerala__       Kerala കേരളം   \n",
              "3            450142621  northwestglock  NorthwestGlockman   \n",
              "4  1351955339894145024  Beetle25521100             Beetle   \n",
              "\n",
              "                                               place  \\\n",
              "0                                                NaN   \n",
              "1                                                NaN   \n",
              "2                                                NaN   \n",
              "3  Place(id='d44cb984bf75455e', fullName='Lake St...   \n",
              "4                                                NaN   \n",
              "\n",
              "                                               tweet language  \\\n",
              "0  @GlennYoungkin Wait what...? Like weaponizing ...       en   \n",
              "1  @ani30oct It won't be tabled. Every vote bank ...       en   \n",
              "2  ShashiTharoor: 2/2 My 2014 Private Members' Bi...       en   \n",
              "3  @JeremyRedfernFL The Supreme Court already rul...       en   \n",
              "4  @sardesairajdeep Supreme court is impotent. Th...       en   \n",
              "\n",
              "                                            mentions  ... retweets_count  \\\n",
              "0  [User(username='GlennYoungkin', id=12760483305...  ...              0   \n",
              "1  [User(username='ani30oct', id=58516766, displa...  ...              0   \n",
              "2  [User(username='INCIndia', id=1153045459, disp...  ...              0   \n",
              "3  [User(username='JeremyRedfernFL', id=65995404,...  ...              0   \n",
              "4  [User(username='sardesairajdeep', id=56304605,...  ...              0   \n",
              "\n",
              "   likes_count  hashtags  cashtags  \\\n",
              "0            0       NaN       NaN   \n",
              "1            0       NaN       NaN   \n",
              "2            0       NaN       NaN   \n",
              "3            0       NaN       NaN   \n",
              "4            0       NaN       NaN   \n",
              "\n",
              "                                              source  retweet  quote_url  \\\n",
              "0  <a href=\"http://twitter.com/download/android\" ...      NaN        NaN   \n",
              "1  <a href=\"http://twitter.com/download/android\" ...      NaN        NaN   \n",
              "2  <a href=\"https://ifttt.com\" rel=\"nofollow\">IFT...      NaN        NaN   \n",
              "3  <a href=\"http://twitter.com/download/iphone\" r...      NaN        NaN   \n",
              "4  <a href=\"https://mobile.twitter.com\" rel=\"nofo...      NaN        NaN   \n",
              "\n",
              "                              reply_to   reply_to_id  view_count  \n",
              "0    https://twitter.com/GlennYoungkin  1.641582e+18         NaN  \n",
              "1         https://twitter.com/ani30oct  1.641659e+18         NaN  \n",
              "2                                  NaN           NaN         NaN  \n",
              "3  https://twitter.com/JeremyRedfernFL  1.641265e+18         NaN  \n",
              "4  https://twitter.com/sardesairajdeep  1.641304e+18         1.0  \n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('./custom_twitter_trend_dataset.csv')\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "json_object = df2.to_json()\n",
        "\n",
        "# print(json_object)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "\n",
        "# jsonobjc = json.dumps(json_object)\n",
        "# data_folder = Path(\"\")\n",
        "# file_to_open = data_folder / \"jsonobjtrend.json\"\n",
        "# file = open(file_to_open, \"w\")\n",
        "# file.write(jsonobjc)\n",
        "# file.close()\n",
        "\n",
        "if (json_object):\n",
        "    # Writing to json\n",
        "    data_folder = Path(\"\")\n",
        "    file_to_open = data_folder / \"jsonobjtrend.json\"\n",
        "    file = open(file_to_open, \"w\")\n",
        "    file.write(json_object)\n",
        "    file.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [],
      "source": [
        "# unique accounts\n",
        "# unique messages\n",
        "# bot list by hour\n",
        "# human list by hour\n",
        "# ok."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
